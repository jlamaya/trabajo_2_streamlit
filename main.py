import os
from typing import Tuple, Dict, Any

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
from groq import Groq

# ======================================
# Configuraci√≥n de p√°gina y estilos
# ======================================
st.set_page_config(page_title="EDA + LLM (Coffee Sales)", page_icon="üìä", layout="wide")
sns.set_theme(style="whitegrid")

# ======================================
# Utilidades LLM (Groq)
# ======================================
def ensure_groq() -> Groq:
    key = st.session_state.get("GROQ_API_KEY") or os.getenv("GROQ_API_KEY")
    if not key:
        st.error("‚ö†Ô∏è Ingresa tu GROQ_API_KEY en la barra lateral.")
        st.stop()
    return Groq(api_key=key)

def ask_groq(messages, model: str = "llama-3.1-8b-instant", temperature: float = 0.2) -> str:
    client = ensure_groq()
    resp = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
    )
    return resp.choices[0].message.content.strip()

# ======================================
# EDA Helpers
# ======================================
EXPECTED_COLS = [
    "hour_of_day","cash_type","money","coffee_name","Time_of_Day",
    "Weekday","Month_name","Weekdaysort","Monthsort","Date","Time"
]

def validate_dataset(df: pd.DataFrame) -> Tuple[bool, str]:
    msg = []
    if df.shape[0] < 300:
        msg.append(f"- El dataset tiene {df.shape[0]} filas (se recomendan ‚â• 300).")
    if df.shape[1] < 6:
        msg.append(f"- El dataset tiene {df.shape[1]} columnas (se recomiendan ‚â• 6).")
    missing = [c for c in EXPECTED_COLS if c not in df.columns]
    if missing:
        msg.append(f"- Faltan columnas esperadas: {missing}")
    return (len(msg) == 0, "\n".join(msg))

def cast_types(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    for c in ["hour_of_day","money","Weekdaysort","Monthsort"]:
        if c in out.columns:
            out[c] = pd.to_numeric(out[c], errors="coerce")
    if "Date" in out.columns:
        out["Date"] = pd.to_datetime(out["Date"], errors="coerce", infer_datetime_format=True)
    return out

def iqr_outlier_mask(series: pd.Series, k: float = 1.5) -> pd.Series:
    s = series.dropna()
    if s.empty:
        return pd.Series([False]*len(series), index=series.index)
    q1, q3 = np.percentile(s, [25, 75])
    iqr = q3 - q1
    low, high = q1 - k*iqr, q3 + k*iqr
    return (series < low) | (series > high)

def compute_insights(df: pd.DataFrame) -> Dict[str, Any]:
    """ Calcula insights clave para UI/LLM. """
    insights = {}

    if {"coffee_name","money"} <= set(df.columns):
        top_coffee_count = df["coffee_name"].value_counts().head(10)
        top_coffee_money = df.groupby("coffee_name")["money"].sum().sort_values(ascending=False).head(10)
        insights["top_coffee_count"] = top_coffee_count.to_dict()
        insights["top_coffee_money"] = top_coffee_money.to_dict()

    if {"hour_of_day","money"} <= set(df.columns):
        money_by_hour = df.groupby("hour_of_day")["money"].sum().sort_values(ascending=False)
        insights["best_hour_by_money"] = money_by_hour.index[0] if not money_by_hour.empty else None
        insights["money_by_hour"] = money_by_hour.sort_index().to_dict()

    if {"Weekday","money"} <= set(df.columns):
        money_by_day = df.groupby("Weekday")["money"].sum().sort_values(ascending=False)
        insights["best_weekday_by_money"] = money_by_day.index[0] if not money_by_day.empty else None
        insights["money_by_weekday"] = money_by_day.to_dict()

    if {"cash_type","money"} <= set(df.columns):
        money_by_cash = df.groupby("cash_type")["money"].sum().sort_values(ascending=False)
        total_money = float(money_by_cash.sum()) if money_by_cash.size else 0.0
        share = (money_by_cash / total_money * 100).round(2) if total_money else money_by_cash
        insights["cash_type_total"] = money_by_cash.to_dict()
        insights["cash_type_share"] = share.to_dict()

    if {"Monthsort","Month_name","money"} <= set(df.columns):
        tmp = df.groupby(["Monthsort","Month_name"])["money"].sum().reset_index()
        tmp = tmp.sort_values(["Monthsort","Month_name"])
        if not tmp.empty:
            best_row = tmp.loc[tmp["money"].idxmax()]
            insights["best_month"] = str(best_row["Month_name"])
            insights["money_by_month"] = dict(zip(tmp["Month_name"], tmp["money"]))

    # Rango de fechas si existe
    if "Date" in df.columns:
        insights["date_min"] = str(pd.to_datetime(df["Date"]).min())
        insights["date_max"] = str(pd.to_datetime(df["Date"]).max())

    return insights

def insights_to_bullets(ins: Dict[str, Any]) -> str:
    """ Resume dict de insights a texto legible. """
    lines = []
    if ins.get("best_hour_by_money") is not None:
        lines.append(f"- Hora con mayores ingresos: {int(ins['best_hour_by_money'])}.")
    if ins.get("best_weekday_by_money"):
        lines.append(f"- D√≠a con mayores ingresos: {ins['best_weekday_by_money']}.")
    if ins.get("best_month"):
        lines.append(f"- Mes m√°s fuerte en ingresos: {ins['best_month']}.")
    if "cash_type_share" in ins:
        parts = ", ".join([f"{k}: {v:.2f}%" for k, v in ins["cash_type_share"].items()])
        if parts:
            lines.append(f"- Participaci√≥n por m√©todo de pago: {parts}.")
    if "top_coffee_count" in ins and ins["top_coffee_count"]:
        top = list(ins["top_coffee_count"].items())[:3]
        lines.append("- Caf√©s m√°s vendidos (cantidad): " + ", ".join([f"{k} ({v})" for k, v in top]) + ".")
    if "top_coffee_money" in ins and ins["top_coffee_money"]:
        topm = list(ins["top_coffee_money"].items())[:3]
        lines.append("- Caf√©s con m√°s ingresos: " + ", ".join([f"{k}" for k, _ in topm]) + ".")
    if ins.get("date_min") or ins.get("date_max"):
        lines.append(f"- Rango de fechas: {ins.get('date_min')} ‚Üí {ins.get('date_max')}.")
    return "\n".join(lines) if lines else "(Sin insights calculables)"

def build_llm_context(df: pd.DataFrame, insights: Dict[str, Any], max_cat_levels: int = 15) -> Dict[str, Any]:
    """
    Construye un contexto compacto para el LLM basado en datos e insights.
    Incluye: esquema, nulos, stats num√©ricas, conteos top de categ√≥ricas,
    agregados clave y combinaciones relevantes.
    """
    context: Dict[str, Any] = {}
    context["shape"] = {"rows": int(df.shape[0]), "cols": int(df.shape[1])}
    context["schema"] = {c: str(df[c].dtype) for c in df.columns}
    context["nulls"] = df.isnull().sum().to_dict()

    # Stats num√©ricas
    num_cols = df.select_dtypes(include=np.number).columns.tolist()
    if num_cols:
        desc = df[num_cols].describe().round(3).to_dict()
        context["numeric_describe"] = desc

    # Conteos top de categ√≥ricas
    cat_cols = [c for c in df.columns if c not in num_cols]
    top_counts = {}
    for c in cat_cols:
        vc = df[c].astype(str).value_counts().head(max_cat_levels).to_dict()
        top_counts[c] = vc
    context["categorical_top_counts"] = top_counts

    # Agregados clave
    context["aggregates"] = {}

    if {"hour_of_day","money"} <= set(df.columns):
        context["aggregates"]["money_by_hour"] = (
            df.groupby("hour_of_day")["money"].sum().sort_index().round(3).to_dict()
        )
    if {"Weekday","money"} <= set(df.columns):
        context["aggregates"]["money_by_weekday"] = (
            df.groupby("Weekday")["money"].sum().round(3).to_dict()
        )
    if {"Monthsort","Month_name","money"} <= set(df.columns):
        tmp = df.groupby(["Monthsort","Month_name"])["money"].sum().reset_index().sort_values("Monthsort")
        context["aggregates"]["money_by_month"] = dict(zip(tmp["Month_name"], tmp["money"].round(3)))
    if {"cash_type","money"} <= set(df.columns):
        money_by_cash = df.groupby("cash_type")["money"].sum()
        total = float(money_by_cash.sum()) if money_by_cash.size else 0.0
        share = (money_by_cash / total * 100).round(2) if total else money_by_cash
        context["aggregates"]["money_by_cash_total"] = money_by_cash.round(3).to_dict()
        context["aggregates"]["money_by_cash_share"] = share.to_dict()

    # üî• Agregados cruzados (para preguntas espec√≠ficas)
    if {"coffee_name","Month_name"} <= set(df.columns):
        cross = df.groupby(["Month_name","coffee_name"])["money"].sum().reset_index()
        pivot = {}
        for month in cross["Month_name"].unique():
            subset = cross[cross["Month_name"] == month]
            pivot[month] = dict(zip(subset["coffee_name"], subset["money"].round(3)))
        context["aggregates"]["money_by_coffee_and_month"] = pivot

    if {"coffee_name","Weekday"} <= set(df.columns):
        cross = df.groupby(["Weekday","coffee_name"])["money"].sum().reset_index()
        pivot = {}
        for day in cross["Weekday"].unique():
            subset = cross[cross["Weekday"] == day]
            pivot[day] = dict(zip(subset["coffee_name"], subset["money"].round(3)))
        context["aggregates"]["money_by_coffee_and_weekday"] = pivot

    if {"coffee_name","hour_of_day"} <= set(df.columns):
        cross = df.groupby(["hour_of_day","coffee_name"])["money"].sum().reset_index()
        pivot = {}
        for hour in cross["hour_of_day"].unique():
            subset = cross[cross["hour_of_day"] == hour]
            pivot[int(hour)] = dict(zip(subset["coffee_name"], subset["money"].round(3)))
        context["aggregates"]["money_by_coffee_and_hour"] = pivot

    # Insights ya calculados
    context["insights"] = insights
    return context

def answer_with_context(question: str, context: Dict[str, Any], model: str, temperature: float = 0.2) -> str:
    """
    Responde usando SOLO el contexto. Si falta info, debe decirlo.
    """
    system = (
        "Eres un analista de datos. Debes responder SOLO usando el contexto proporcionado. "
        "Si el contexto no tiene la informaci√≥n necesaria, dilo expl√≠citamente y explica qu√© faltar√≠a. "
        "Cuando cites cifras, incluye unidades cuando sea obvio (por ejemplo, 'money' como monto). "
        "Si haces un c√°lculo, mu√©stralo brevemente."
    )
    user = f"""CONTEXTO (JSON compacto):
{context}

PREGUNTA:
{question}

INSTRUCCIONES DE RESPUESTA:
- Responde en espa√±ol, breve y claro.
- No inventes datos m√°s all√° del contexto.
- Si la respuesta requiere datos que no est√°n, dilo y sugiere qu√© c√°lculo o dato faltar√≠a.
"""
    return ask_groq(
        messages=[{"role": "system", "content": system},
                  {"role": "user", "content": user}],
        model=model,
        temperature=temperature
    )

# ======================================
# UI ‚Äî Barra lateral
# ======================================
with st.sidebar:
    st.header("üîë Configuraci√≥n")
    api_key = st.text_input("GROQ_API_KEY", type="password")
    if api_key:
        st.session_state["GROQ_API_KEY"] = api_key

    st.header("ü§ñ Modelo Groq")
    model = st.selectbox("Modelo", ["llama-3.1-8b-instant","llama-3.1-70b-versatile"], index=0)
    temperature = st.slider("Temperature", 0.0, 1.0, 0.2, 0.05,
                            help="M√°s bajo = respuestas m√°s deterministas; m√°s alto = m√°s creativas.")

# ======================================
# UI ‚Äî Contenido principal
# ======================================
st.title("üìä EDA + LLM sobre Ventas de Caf√©")
st.caption("Sube un CSV (‚â•300 filas, ‚â•6 columnas). El EDA mostrar√° estructura, nulos, outliers y visualizaciones. Luego, conversa con un LLM usando los insights.")

uploaded = st.file_uploader("üìÇ Sube tu CSV (obligatorio)", type=["csv"])

if uploaded is None:
    st.warning("‚ö†Ô∏è Debes subir un archivo CSV para continuar.")
    st.stop()

# Carga y validaci√≥n
df_raw = pd.read_csv(uploaded)
df = cast_types(df_raw)

ok, warn = validate_dataset(df)
if not ok:
    st.warning(f"Recomendaciones/Advertencias:\n{warn}")

# =======================
# Vista r√°pida
# =======================
st.subheader("üëÄ Vista previa")
st.dataframe(df.head())

c1, c2, c3 = st.columns(3)
with c1:
    st.metric("Filas", df.shape[0])
with c2:
    st.metric("Columnas", df.shape[1])
with c3:
    num_cols = df.select_dtypes(include=np.number).columns.tolist()
    st.metric("Cols num√©ricas", len(num_cols))

st.subheader("üß± Tipos de datos")
st.write(df.dtypes)

# =======================
# Nulos y descriptivos
# =======================
st.subheader("üîé Valores nulos por columna")
nulls = df.isnull().sum()
st.write(nulls)

fig, ax = plt.subplots()
nulls.plot(kind="bar", ax=ax)
ax.set_title("Conteo de nulos por columna")
ax.set_ylabel("Nulos")
st.pyplot(fig)

st.subheader("üìà Estad√≠sticas descriptivas (num√©ricas)")
if num_cols:
    st.write(df[num_cols].describe().T)
else:
    st.info("No se detectaron columnas num√©ricas.")

# =======================
# Outliers (IQR) en money
# =======================
if "money" in df.columns:
    st.subheader("üö© Detecci√≥n de at√≠picos (IQR) en 'money'")
    mask_out = iqr_outlier_mask(df["money"])
    st.write(f"Filas at√≠picas en 'money': {int(mask_out.sum())}")
    if mask_out.sum() > 0:
        st.dataframe(df.loc[mask_out].head())

# =======================
# Visualizaciones
# =======================
st.subheader("üìä Visualizaciones")

viz1, viz2 = st.columns(2)

with viz1:
    if "money" in df.columns:
        st.markdown("**Distribuci√≥n de 'money'**")
        fig, ax = plt.subplots()
        sns.histplot(df["money"].dropna(), kde=True, ax=ax)
        ax.set_xlabel("money")
        st.pyplot(fig)

    if {"coffee_name"} <= set(df.columns):
        st.markdown("**Top caf√©s vendidos (conteo)**")
        top_c = df["coffee_name"].value_counts().head(10)
        fig, ax = plt.subplots()
        sns.barplot(x=top_c.values, y=top_c.index, ax=ax)
        ax.set_xlabel("Cantidad")
        ax.set_ylabel("Caf√©")
        st.pyplot(fig)

with viz2:
    if {"cash_type","money"} <= set(df.columns):
        st.markdown("**'money' por 'cash_type' (boxplot)**")
        fig, ax = plt.subplots()
        sns.boxplot(data=df, x="cash_type", y="money", ax=ax)
        ax.set_xlabel("cash_type")
        ax.set_ylabel("money")
        st.pyplot(fig)

    if {"hour_of_day","money"} <= set(df.columns):
        st.markdown("**Ingresos por hora (suma)**")
        by_hour = df.groupby("hour_of_day")["money"].sum().reset_index().sort_values("hour_of_day")
        fig, ax = plt.subplots()
        sns.lineplot(data=by_hour, x="hour_of_day", y="money", marker="o", ax=ax)
        ax.set_xlabel("hour_of_day")
        ax.set_ylabel("money (suma)")
        st.pyplot(fig)

# Heatmap hora x d√≠a
if {"Weekdaysort","hour_of_day","money","Weekday"} <= set(df.columns):
    st.markdown("**Heatmap: Suma de 'money' por (d√≠a de semana √ó hora)**")
    pivot = df.pivot_table(index="Weekdaysort", columns="hour_of_day", values="money", aggfunc="sum")
    # Etiquetas legibles si hay Weekday
    day_names = (df[["Weekdaysort","Weekday"]]
                 .dropna()
                 .drop_duplicates()
                 .sort_values("Weekdaysort"))
    if not day_names.empty:
        pivot.index = [day_names.set_index("Weekdaysort").loc[i, "Weekday"]
                       if i in day_names["Weekdaysort"].values else i
                       for i in pivot.index]
    fig, ax = plt.subplots(figsize=(8, 5))
    sns.heatmap(pivot, cmap="Blues", ax=ax)
    ax.set_xlabel("hour_of_day")
    ax.set_ylabel("Weekday")
    st.pyplot(fig)

# Barras por mes
if {"Monthsort","Month_name","money"} <= set(df.columns):
    st.markdown("**Ingresos por mes (suma)**")
    by_month = df.groupby(["Monthsort","Month_name"])["money"].sum().reset_index().sort_values("Monthsort")
    fig, ax = plt.subplots()
    sns.barplot(data=by_month, x="Month_name", y="money", ax=ax)
    ax.set_xlabel("Month")
    ax.set_ylabel("money (suma)")
    plt.xticks(rotation=45)
    st.pyplot(fig)

# =======================
# Insights + LLM (resumen)
# =======================
st.subheader("üß† Insights y LLM")

ins = compute_insights(df)
ins_bullets = insights_to_bullets(ins)
with st.expander("Ver insights calculados (para contexto del LLM)"):
    st.markdown(ins_bullets)

summary_prompt = f"""
Eres un analista de datos. Te doy la estructura b√°sica de un dataset de ventas de caf√© y algunos insights calculados.

Dimensiones: {df.shape[0]} filas √ó {df.shape[1]} columnas.
Tipos de datos (por columna): {df.dtypes.to_dict()}
Nulos por columna: {df.isnull().sum().to_dict()}

Insights calculados:
{ins_bullets}

Por favor, entrega:
1) Un resumen ejecutivo (3-5 vi√±etas) de patrones clave (horas, d√≠as, meses, caf√©s y m√©todo de pago).
2) Sugerencias de hip√≥tesis o pr√≥ximos an√°lisis a realizar (2-3 puntos).
Responde en espa√±ol, claro y sin inventar datos que no est√©n respaldados por lo anterior.
"""

if st.button("üìÑ Generar resumen con LLM"):
    with st.spinner("Consultando Groq‚Ä¶"):
        resumen = ask_groq(
            messages=[{"role": "user", "content": summary_prompt}],
            model=model,
            temperature=temperature
        )
    st.markdown("### Resumen (LLM)")
    st.write(resumen)
    st.session_state["eda_summary"] = resumen

# =======================
# Q&A BASADO EN DATOS (CON CONTEXTO)
# =======================
st.subheader("üí¨ Pregunta al agente (basado en datos e insights)")

# Construimos el contexto SIEMPRE despu√©s del EDA
llm_context = build_llm_context(df, insights=ins, max_cat_levels=15)

with st.expander("Ver contexto que recibe el LLM (JSON compacto)"):
    st.json(llm_context)

user_q = st.text_input(
    "Escribe tu pregunta (ej.: ¬øQu√© caf√© conviene promocionar en la ma√±ana? ¬øQu√© d√≠a y hora dejan m√°s ingresos?)"
)
if st.button("Preguntar al LLM con contexto"):
    if not user_q.strip():
        st.warning("Escribe una pregunta primero.")
    else:
        with st.spinner("Groq pensando‚Ä¶"):
            ans = answer_with_context(user_q, llm_context, model=model, temperature=temperature)
        st.markdown("**Respuesta del LLM (basada SOLO en el contexto):**")
        st.write(ans)
